@IEEEtranBSTCTL{IEEEexample:BSTcontrol,
CTLuse_url = "no",
}

@book{em:86,
  editor  = "Engelmore, Robert and Morgan, Anthony",
  title   = "Blackboard Systems",
  year    = 1986,
  address = "Reading, Mass.",
  publisher = "Addison-Wesley",
}

@inproceedings{c:83,
  author  = "Clancey, William J.",
  year    = 1983,
  title   = "{Communication, Simulation, and Intelligent
Agents: Implications of Personal Intelligent Machines
for Medical Education}",
  booktitle="Proceedings of the Eighth International Joint Conference on Artificial Intelligence {(IJCAI-83)}", 
  pages   = "556-560",
  address = "Menlo Park, Calif",
  publisher = "{IJCAI Organization}",
}
@inproceedings{c:84,
  author  = "Clancey, William J.",
  year    = 1984,
  title   = "{Classification Problem Solving}",
  booktitle = "Proceedings of the Fourth National 
              Conference on Artificial Intelligence",
  pages   = "45-54",
  address = "Menlo Park, Calif.",
  publisher="AAAI Press",
}
@article{r:80,
  author = {Robinson, Arthur L.},
  title = {New Ways to Make Microcircuits Smaller},
  volume = {208},
  number = {4447},
  pages = {1019--1022},
  year = {1980},
  doi = {10.1126/science.208.4447.1019},
  publisher = {American Association for the Advancement of Science},
  issn = {0036-8075},
  URL = {https://science.sciencemag.org/content/208/4447/1019},
  eprint = {https://science.sciencemag.org/content/208/4447/1019.full.pdf},
  journal = {Science},
}
@article{r:80x,
  author  = "Robinson, Arthur L.",
  year    = 1980,
  title   = "{New Ways to Make Microcircuits Smaller---Duplicate Entry}",
  journal = "Science",
  volume  =  208,
  pages   = "1019-1026",
}
@article{hcr:83,
title = {Strategic explanations for a diagnostic consultation system},
journal = {International Journal of Man-Machine Studies},
volume = {20},
number = {1},
pages = {3-19},
year = {1984},
issn = {0020-7373},
doi = {https://doi.org/10.1016/S0020-7373(84)80003-6},
url = {https://www.sciencedirect.com/science/article/pii/S0020737384800036},
author = {Diane Warner Hasling and William J. Clancey and Glenn Rennels},
abstract = {This article examines the problem of automatte explanation of reasoning, especially as it relates to expert systems. By explanation we mean the ability of a program to discuss what it is doing in some understandable way. We first present a general framework in which to view explanation and review some of the research done in this area. We then focus on the explanation system for NEOMYCIN, a medical consultation program. A consultation program interactively helps a user to solve a problem. Our goal is to have NEOMYCIN explain its problem-solving strategies. An explanation of strategy describes the plan the program is using to reach a solution. Such an explanation is usually concrete, referring to aspects of the current problem situation. Abstract explanations articulate a general principle, which can be applied in different situations; such explanations are useful in teaching and in explaining by analogy. We describe the aspects of NEOMYCIN that make abstract strategic explanations possible—the representation of strategic knowledge explicitly and separately from domain knowledge— and demonstrate how this representation can be used to generate explanations.}
}
@article{hcrt:83,
  author  = "Hasling, Diane Warner and Clancey, William J. and Rennels, Glenn R. and Test, Thomas",
  year    = 1983,
  title   = "{Strategic Explanations in Consultation---Duplicate}",
  journal = "The International Journal of Man-Machine Studies",
  volume  = 20,
  number  = 1,
  pages   = "3-19",
}
@techreport{r:86,
  author  = "Rice, James",
  year    = 1986,
  title   = "{Poligon: A System for Parallel Problem Solving}",
  type    = "Technical Report", 
  number  = "KSL-86-19", 
  institution = "Dept.\ of Computer Science, Stanford Univ.",
}
@phdthesis{c:79,
  author  = "Clancey, William J.",
  year    = 1979,
  title   = "{Transfer of Rule-Based Expertise
through a Tutorial Dialogue}",
  type    = "{Ph.D.} diss.",
  school  = "Dept.\ of Computer Science, Stanford Univ.",
  address = "Stanford, Calif.",
}
@unpublished{c:21,
  author  = "Clancey, William J.",
  title   = "{The Engineering of Qualitative Models}",
  year    = 2021,
  note    = "Forthcoming",
}
@misc{c:22,
      title={Crime and punishment in scientific research}, 
      author={Mathieu Bouville},
      year={2008},
      eprint={0803.4058},
      archivePrefix={arXiv},
      primaryClass={physics.soc-ph}
}
@misc{c:23,
  title        = "Pluto: The 'Other' Red Planet",
  author       = "{NASA}",
  howpublished = "\url{https://www.nasa.gov/nh/pluto-the-other-red-planet}",
  year         = 2015,
  note         = "Accessed: 2018-12-06"
}


@misc{PrivGAN2019,
  doi = {10.48550/ARXIV.2001.00071},
  
  url = {https://arxiv.org/abs/2001.00071},
  
  author = {Mukherjee, Sumit and Xu, Yixi and Trivedi, Anusua and Ferres, Juan Lavista},
  
  keywords = {Machine Learning (cs.LG), Cryptography and Security (cs.CR), Computer Vision and Pattern Recognition (cs.CV), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {privGAN: Protecting GANs from membership inference attacks at low cost},
  
  publisher = {arXiv},
  
  year = {2020},
  
  copyright = {Creative Commons Attribution 4.0 International}
}



@misc{Fedprox2018,
  doi = {10.48550/ARXIV.1812.06127},
  
  url = {https://arxiv.org/abs/1812.06127},
  
  author = {Li, Tian and Sahu, Anit Kumar and Zaheer, Manzil and Sanjabi, Maziar and Talwalkar, Ameet and Smith, Virginia},
  
  keywords = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Federated Optimization in Heterogeneous Networks},
  
  publisher = {arXiv},
  
  year = {2018},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@misc{FedavgGAN2019,
  doi = {10.48550/ARXIV.1911.06679},
  
  url = {https://arxiv.org/abs/1911.06679},
  
  author = {Augenstein, Sean and McMahan, H. Brendan and Ramage, Daniel and Ramaswamy, Swaroop and Kairouz, Peter and Chen, Mingqing and Mathews, Rajiv and Arcas, Blaise Aguera y},
  
  keywords = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Generative Models for Effective ML on Private, Decentralized Datasets},
  
  publisher = {arXiv},
  
  year = {2019},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@article{zhao2018fedNon_IID,
  title={Federated learning with non-iid data},
  author={Zhao, Yue and Li, Meng and Lai, Liangzhen and Suda, Naveen and Civin, Damon and Chandra, Vikas},
  journal={arXiv preprint arXiv:1806.00582},
  year={2018}
}

@inproceedings{MDGAN2019,
	doi = {10.1109/ipdps.2019.00095},
  
	year = 2019,
	month = {may},
  
	publisher = {{IEEE}
},
  
	author = {Corentin Hardy and Erwan Le Merrer and Bruno Sericola},
  
	title = {{MD}-{GAN}: Multi-Discriminator Generative Adversarial Networks for Distributed Datasets},
  
	booktitle = {2019 {IEEE} International Parallel and Distributed Processing Symposium ({IPDPS})}
}


@inproceedings{InceptionScore2016,
 author = {Salimans, Tim and Goodfellow, Ian and Zaremba, Wojciech and Cheung, Vicki and Radford, Alec and Chen, Xi and Chen, Xi},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {D. Lee and M. Sugiyama and U. Luxburg and I. Guyon and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Improved Techniques for Training GANs},
 url = {https://proceedings.neurips.cc/paper/2016/file/8a3363abe792db2d8761d6403605aeb7-Paper.pdf},
 volume = {29},
 year = {2016}
}




@inproceedings{FidScore2017,
 author = {Heusel, Martin and Ramsauer, Hubert and Unterthiner, Thomas and Nessler, Bernhard and Hochreiter, Sepp},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium},
 url = {https://proceedings.neurips.cc/paper/2017/file/8a1d694707eb0fefe65871369074926d-Paper.pdf},
 volume = {30},
 year = {2017}
}


@inproceedings{MCAttackHilprecht2019,
author = {Hilprecht, Benjamin and Härterich, Martin and Bernau, Daniel},
year = {2019},
month = {07},
pages = {},
title = {Monte Carlo and Reconstruction Membership Inference Attacks against Generative Models},
volume = {2019},
journal = {Proceedings on Privacy Enhancing Technologies},
doi = {10.2478/popets-2019-0067}
}


@misc{WBAttack2018,
      title={LOGAN: Membership Inference Attacks Against Generative Models}, 
      author={Jamie Hayes and Luca Melis and George Danezis and Emiliano De Cristofaro},
      year={2018},
      eprint={1705.07663},
      archivePrefix={arXiv},
      primaryClass={cs.CR}
}

@unknown{SkewDist2022,
author = {Zhang, Zhenyuan},
year = {2022},
month = {01},
pages = {},
title = {FedDTG:Federated Data-Free Knowledge Distillation via Three-Player Generative Adversarial Networks}
}



@InProceedings{DistImabalance2019,
  title = 	 {{B}ayesian Nonparametric Federated Learning of Neural Networks},
  author =       {Yurochkin, Mikhail and Agarwal, Mayank and Ghosh, Soumya and Greenewald, Kristjan and Hoang, Nghia and Khazaeni, Yasaman},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  pages = 	 {7252--7261},
  year = 	 {2019},
  editor = 	 {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  volume = 	 {97},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--15 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v97/yurochkin19a/yurochkin19a.pdf},
  url = 	 {https://proceedings.mlr.press/v97/yurochkin19a.html},
  abstract = 	 {In federated learning problems, data is scattered across different servers and exchanging or pooling it is often impractical or prohibited. We develop a Bayesian nonparametric framework for federated learning with neural networks. Each data server is assumed to provide local neural network weights, which are modeled through our framework. We then develop an inference approach that allows us to synthesize a more expressive global network without additional supervision, data pooling and with as few as a single communication round. We then demonstrate the efficacy of our approach on federated learning problems simulated from two popular image classification datasets.}
}


@article{kairouz2021advances,
  title={Advances and open problems in federated learning},
  author={Kairouz, Peter and McMahan, H Brendan and Avent, Brendan and Bellet, Aur{\'e}lien and Bennis, Mehdi and Bhagoji, Arjun Nitin and Bonawitz, Kallista and Charles, Zachary and Cormode, Graham and Cummings, Rachel and others},
  journal={Foundations and Trends{\textregistered} in Machine Learning},
  volume={14},
  number={1--2},
  pages={1--210},
  year={2021},
  publisher={Now Publishers, Inc.}
}


@inproceedings{DistLabelQinbin2021,
  title     = {Practical One-Shot Federated Learning for Cross-Silo Setting},
  author    = {Li, Qinbin and He, Bingsheng and Song, Dawn},
  booktitle = {Proceedings of the Thirtieth International Joint Conference on
               Artificial Intelligence, {IJCAI-21}},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},
  editor    = {Zhi-Hua Zhou},
  pages     = {1484--1490},
  year      = {2021},
  month     = {8},
  note      = {Main Track},
  doi       = {10.24963/ijcai.2021/205},
  url       = {https://doi.org/10.24963/ijcai.2021/205},
}


@inproceedings{DistLabelWang2020,
author = {Wang, Jianyu and Liu, Qinghua and Liang, Hao and Joshi, Gauri and Poor, H. Vincent},
title = {Tackling the Objective Inconsistency Problem in Heterogeneous Federated Optimization},
year = {2020},
isbn = {9781713829546},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {In federated learning, heterogeneity in the clients' local datasets and computation speeds results in large variations in the number of local updates performed by each client in each communication round. Naive weighted aggregation of such models causes objective inconsistency, that is, the global model converges to a stationary point of a mismatched objective function which can be arbitrarily different from the true objective. This paper provides a general framework to analyze the convergence of heterogeneous federated optimization algorithms. It subsumes previously proposed methods such as FedAvg and FedProx, and provides the first principled understanding of the solution bias and the convergence slowdown due to objective inconsistency. Using insights from this analysis, we propose FedNova, a normalized averaging method that eliminates objective inconsistency while preserving fast error convergence.},
booktitle = {Proceedings of the 34th International Conference on Neural Information Processing Systems},
articleno = {638},
numpages = {13},
location = {Vancouver, BC, Canada},
series = {NIPS'20}
}




@inproceedings{DistLabelHongyi2020,
  author    = {Hongyi Wang and
               Mikhail Yurochkin and
               Yuekai Sun and
               Dimitris S. Papailiopoulos and
               Yasaman Khazaeni},
  title     = {Federated Learning with Matched Averaging},
  booktitle = {8th International Conference on Learning Representations, {ICLR} 2020,
               Addis Ababa, Ethiopia, April 26-30, 2020},
  publisher = {OpenReview.net},
  year      = {2020},
  url       = {https://openreview.net/forum?id=BkluqlSFDS},
  timestamp = {Thu, 07 May 2020 17:11:48 +0200},
  biburl    = {https://dblp.org/rec/conf/iclr/WangYSPK20.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{DistLabelLarochelle2020,
 author = {Lin, Tao and Kong, Lingjing and Stich, Sebastian U and Jaggi, Martin},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {2351--2363},
 publisher = {Curran Associates, Inc.},
 title = {Ensemble Distillation for Robust Model Fusion in Federated Learning},
 url = {https://proceedings.neurips.cc/paper/2020/file/18df51b97ccd68128e994804f3eccc87-Paper.pdf},
 volume = {33},
 year = {2020}
}


@inproceedings{adam2014,
  author    = {Diederik P. Kingma and
               Jimmy Ba},
  editor    = {Yoshua Bengio and
               Yann LeCun},
  title     = {Adam: {A} Method for Stochastic Optimization},
  booktitle = {3rd International Conference on Learning Representations, {ICLR} 2015,
               San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings},
  year      = {2015},
  url       = {http://arxiv.org/abs/1412.6980},
  timestamp = {Thu, 25 Jul 2019 14:25:37 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/KingmaB14.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@INPROCEEDINGS{InceptionV3_2015,
  author={Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jon and Wojna, Zbigniew},
  booktitle={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Rethinking the Inception Architecture for Computer Vision}, 
  year={2016},
  volume={},
  number={},
  pages={2818-2826},
  doi={10.1109/CVPR.2016.308}}



@article{ProsConsEval2021,
author = {Borji, Ali},
title = {Pros and Cons of GAN Evaluation Measures: New Developments},
year = {2022},
issue_date = {Jan 2022},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {215},
number = {C},
issn = {1077-3142},
url = {https://doi.org/10.1016/j.cviu.2021.103329},
doi = {10.1016/j.cviu.2021.103329},
journal = {Comput. Vis. Image Underst.},
month = {jan},
numpages = {15},
keywords = {65D17, Deepfakes, GAN evaluation, Generative modeling, 41A05, 41A10, 65D05}
}


@article{dwork_book,
author = {Dwork, Cynthia and Roth, Aaron},
title = {The Algorithmic Foundations of Differential Privacy},
year = {2014},
issue_date = {August 2014},
publisher = {Now Publishers Inc.},
address = {Hanover, MA, USA},
volume = {9},
number = {3–4},
issn = {1551-305X},
url = {https://doi.org/10.1561/0400000042},
doi = {10.1561/0400000042},
journal = {Found. Trends Theor. Comput. Sci.},
month = aug,
pages = {211–407},
numpages = {197}
}


@inproceedings{
DPFedAvg2018,
title={Learning Differentially Private Recurrent Language Models},
author={H. Brendan McMahan and Daniel Ramage and Kunal Talwar and Li Zhang},
booktitle={International Conference on Learning Representations},
year={2018},
url={https://openreview.net/forum?id=BJ0hF1Z0b},
}


@inproceedings{yoon2018pategan,
title={{PATE}-{GAN}: Generating Synthetic Data with Differential Privacy Guarantees},
author={Jinsung Yoon and James Jordon and Mihaela van der Schaar},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=S1zk9iRqF7},
}





@article{GANGoodFellow2014,
author = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
title = {Generative Adversarial Networks},
year = {2020},
issue_date = {November 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {63},
number = {11},
issn = {0001-0782},
url = {https://doi.org/10.1145/3422622},
doi = {10.1145/3422622},
abstract = {Generative adversarial networks are a kind of artificial intelligence algorithm designed to solve the generative modeling problem. The goal of a generative model is to study a collection of training examples and learn the probability distribution that generated them. Generative Adversarial Networks (GANs) are then able to generate more examples from the estimated probability distribution. Generative models based on deep learning are common, but GANs are among the most successful generative models (especially in terms of their ability to generate realistic high-resolution images). GANs have been successfully applied to a wide variety of tasks (mostly in research settings) but continue to present unique challenges and research opportunities because they are based on game theory while most other approaches to generative modeling are based on optimization.},
journal = {Commun. ACM},
month = {oct},
pages = {139–144},
numpages = {6}
}



@InProceedings{FLMcMahan2016,
  title = 	 {{Communication-Efficient Learning of Deep Networks from Decentralized Data}},
  author = 	 {McMahan, Brendan and Moore, Eider and Ramage, Daniel and Hampson, Seth and Arcas, Blaise Aguera y},
  booktitle = 	 {Proceedings of the 20th International Conference on Artificial Intelligence and Statistics},
  pages = 	 {1273--1282},
  year = 	 {2017},
  editor = 	 {Singh, Aarti and Zhu, Jerry},
  volume = 	 {54},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {20--22 Apr},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v54/mcmahan17a/mcmahan17a.pdf},
  url = 	 {https://proceedings.mlr.press/v54/mcmahan17a.html},
  abstract = 	 {Modern mobile devices have access to a wealth of data suitable for learning models, which in turn can greatly improve the user experience on the device. For example, language models can improve speech recognition and text entry, and image models can automatically select good photos. However, this rich data is often privacy sensitive, large in quantity, or both, which may preclude logging to the data center and training there using conventional approaches.  We advocate an alternative that leaves the training data distributed on the mobile devices, and learns a shared model by aggregating locally-computed updates. We term this decentralized approach Federated Learning.  We present a practical method for the federated learning of deep networks based on iterative model averaging, and conduct an extensive empirical evaluation, considering five different model architectures and four datasets. These experiments demonstrate the approach is robust to the unbalanced and non-IID data distributions that are a defining characteristic of this setting. Communication costs are the principal constraint, and we show a reduction in required communication rounds by 10-100x as compared to synchronized stochastic gradient descent. }
}




@INPROCEEDINGS{MemAttackLiu2018,
  author={Liu, Kin Sum and Xiao, Chaowei and Li, Bo and Gao, Jie},
  booktitle={2019 IEEE International Conference on Data Mining (ICDM)}, 
  title={Performing Co-membership Attacks Against Deep Generative Models}, 
  year={2019},
  volume={},
  number={},
  pages={459-467},
  doi={10.1109/ICDM.2019.00056}}


@inproceedings{MemAttackYeom2018,
  title={Privacy risk in machine learning: Analyzing the connection to overfitting},
  author={Yeom, Samuel and Giacomelli, Irene and Fredrikson, Matt and Jha, Somesh},
  booktitle={2018 IEEE 31st computer security foundations symposium (CSF)},
  pages={268--282},
  year={2018},
  organization={IEEE}
}



@inproceedings{ChenGANLeaks_2020,
  title={Gan-leaks: A taxonomy of membership inference attacks against generative models},
  author={Chen, Dingfan and Yu, Ning and Zhang, Yang and Fritz, Mario},
  booktitle={Proceedings of the 2020 ACM SIGSAC conference on computer and communications security},
  pages={343--362},
  year={2020}
}




@inproceedings{MemAttackNasr2018,
  title={Machine learning with membership privacy using adversarial regularization},
  author={Nasr, Milad and Shokri, Reza and Houmansadr, Amir},
  booktitle={Proceedings of the 2018 ACM SIGSAC conference on computer and communications security},
  pages={634--646},
  year={2018}
}

@article{DPGANXie2018,
  title={Differentially private generative adversarial network},
  author={Xie, Liyang and Lin, Kaixiang and Wang, Shu and Wang, Fei and Zhou, Jiayu},
  journal={arXiv preprint arXiv:1802.06739},
  year={2018}
}



@inproceedings{DPSGD2016Abadi,
author = {Abadi, Martin and Chu, Andy and Goodfellow, Ian and McMahan, H. Brendan and Mironov, Ilya and Talwar, Kunal and Zhang, Li},
title = {Deep Learning with Differential Privacy},
year = {2016},
isbn = {9781450341394},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2976749.2978318},
doi = {10.1145/2976749.2978318},
abstract = {Machine learning techniques based on neural networks are achieving remarkable results in a wide variety of domains. Often, the training of models requires large, representative datasets, which may be crowdsourced and contain sensitive information. The models should not expose private information in these datasets. Addressing this goal, we develop new algorithmic techniques for learning and a refined analysis of privacy costs within the framework of differential privacy. Our implementation and experiments demonstrate that we can train deep neural networks with non-convex objectives, under a modest privacy budget, and at a manageable cost in software complexity, training efficiency, and model quality.},
booktitle = {Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security},
pages = {308–318},
numpages = {11},
keywords = {deep learning, differential privacy},
location = {Vienna, Austria},
series = {CCS '16}
}




@unknown{DLNonIID2019,
author = {Yonetani, Ryo and Takahashi, Tomohiro and Hashimoto, Atsushi and Ushiku, Yoshitaka},
year = {2019},
month = {05},
pages = {},
title = {Decentralized Learning of Generative Adversarial Networks from Multi-Client Non-iid Data}
}

@inproceedings{MironovRDP2017,
	doi = {10.1109/csf.2017.11},

  
	year = 2017,
	month = {aug},
  
	publisher = {{IEEE}
},
  
	author = {Ilya Mironov},
  
	title = {R{\'{e}}nyi Differential Privacy},
  
	booktitle = {2017 {IEEE} 30th Computer Security Foundations Symposium ({CSF})}
}





@InProceedings{WangRDP2018,
  title = 	 {Subsampled Renyi Differential Privacy and Analytical Moments Accountant},
  author =       {Wang, Yu-Xiang and Balle, Borja and Kasiviswanathan, Shiva Prasad},
  booktitle = 	 {Proceedings of the Twenty-Second International Conference on Artificial Intelligence and Statistics},
  pages = 	 {1226--1235},
  year = 	 {2019},
  editor = 	 {Chaudhuri, Kamalika and Sugiyama, Masashi},
  volume = 	 {89},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {16--18 Apr},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v89/wang19b/wang19b.pdf},
  url = 	 {https://proceedings.mlr.press/v89/wang19b.html},
  abstract = 	 {We study the problem of subsampling in differential privacy (DP), a question that is the centerpiece behind many successful differentially private machine learning algorithms.  Specifically, we provide a tight upper bound on the Renyi Differential Privacy (RDP) [Mironov 2017] parameters for algorithms that: (1) subsample the dataset, and then (2) applies a randomized mechanism M to the subsample, in terms of the RDP parameters of M and the subsampling probability parameter. Our results generalize the moments accounting technique, developed by [Abadi et al. 2016] for the Gaussian mechanism, to any subsampled RDP mechanism.}
}

@InProceedings{McSherry2006,
author="Dwork, Cynthia
and Kenthapadi, Krishnaram
and McSherry, Frank
and Mironov, Ilya
and Naor, Moni",
editor="Vaudenay, Serge",
title="Our Data, Ourselves: Privacy Via Distributed Noise Generation",
booktitle="Advances in Cryptology - EUROCRYPT 2006",
year="2006",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="486--503",
abstract="In this work we provide efficient distributed protocols for generating shares of random noise, secure against malicious participants. The purpose of the noise generation is to create a distributed implementation of the privacy-preserving statistical databases described in recent papers [14,4,13]. In these databases, privacy is obtained by perturbing the true answer to a database query by the addition of a small amount of Gaussian or exponentially distributed random noise. The computational power of even a simple form of these databases, when the query is just of the form ∑if(di), that is, the sum over all rows i in the database of a function f applied to the data in row i, has been demonstrated in [4]. A distributed implementation eliminates the need for a trusted database administrator.",
isbn="978-3-540-34547-3"
}






@article{GDPRAlbrecht2016,
  title={How the GDPR Will Change the World},
  author={Jan Philipp Albrecht},
  journal={European Data Protection Law Review},
  year={2016},
  volume={2},
  pages={287-289}
}




@article{MedicalGAN_Yi_2019,
title = {Generative adversarial network in medical imaging: A review},
journal = {Medical Image Analysis},
volume = {58},
pages = {101552},
year = {2019},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2019.101552},
url = {https://www.sciencedirect.com/science/article/pii/S1361841518308430},
author = {Xin Yi and Ekta Walia and Paul Babyn},
keywords = {Deep learning, Generative adversarial network, Generative model, Medical imaging, Review},
abstract = {Generative adversarial networks have gained a lot of attention in the computer vision community due to their capability of data generation without explicitly modelling the probability density function. The adversarial loss brought by the discriminator provides a clever way of incorporating unlabeled samples into training and imposing higher order consistency. This has proven to be useful in many cases, such as domain adaptation, data augmentation, and image-to-image translation. These properties have attracted researchers in the medical imaging community, and we have seen rapid adoption in many traditional and novel applications, such as image reconstruction, segmentation, detection, classification, and cross-modality synthesis. Based on our observations, this trend will continue and we therefore conducted a review of recent advances in medical imaging using the adversarial training scheme with the hope of benefiting researchers interested in this technique.}
}



@INPROCEEDINGS{BrainGAN_Han2018,
  author={Han, Changhee and Hayashi, Hideaki and Rundo, Leonardo and Araki, Ryosuke and Shimoda, Wataru and Muramatsu, Shinichi and Furukawa, Yujiro and Mauri, Giancarlo and Nakayama, Hideki},
  booktitle={2018 IEEE 15th International Symposium on Biomedical Imaging (ISBI 2018)}, 
  title={GAN-based synthetic brain MR image generation}, 
  year={2018},
  volume={},
  number={},
  pages={734-738},
  doi={10.1109/ISBI.2018.8363678}}




@phdthesis{Torfi2020PrivacyPreservingSM,
  title={Privacy-Preserving Synthetic Medical Data Generation with Deep Learning},
  author={Torfi, Amirsina},
  year={2020},
  school={Virginia Tech}
}


@INPROCEEDINGS{LiuMemAttack2018,  author={Liu, Kin Sum and Xiao, Chaowei and Li, Bo and Gao, Jie},  booktitle={2019 IEEE International Conference on Data Mining (ICDM)},   title={Performing Co-membership Attacks Against Deep Generative Models},   year={2019},  volume={},  number={},  pages={459-467},  doi={10.1109/ICDM.2019.00056}}


@misc{NIID_GAN2019,
  doi = {10.48550/ARXIV.1905.09684},
  
  url = {https://arxiv.org/abs/1905.09684},
  
  author = {Yonetani, Ryo and Takahashi, Tomohiro and Hashimoto, Atsushi and Ushiku, Yoshitaka},
  
  keywords = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Decentralized Learning of Generative Adversarial Networks from Non-iid Data},
  
  publisher = {arXiv},
  
  year = {2019},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{BenDist2018,
author = {Ben-Nun, Tal and Hoefler, Torsten},
title = {Demystifying Parallel and Distributed Deep Learning: An In-Depth Concurrency Analysis},
year = {2019},
issue_date = {July 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3320060},
doi = {10.1145/3320060},
abstract = {Deep Neural Networks (DNNs) are becoming an important tool in modern computing applications. Accelerating their training is a major challenge and techniques range from distributed algorithms to low-level circuit design. In this survey, we describe the problem from a theoretical perspective, followed by approaches for its parallelization. We present trends in DNN architectures and the resulting implications on parallelization strategies. We then review and model the different types of concurrency in DNNs: from the single operator, through parallelism in network inference and training, to distributed deep learning. We discuss asynchronous stochastic optimization, distributed system architectures, communication schemes, and neural architecture search. Based on those approaches, we extrapolate potential directions for parallelism in deep learning.},
journal = {ACM Comput. Surv.},
month = {aug},
articleno = {65},
numpages = {43},
keywords = {Deep learning, distributed computing, parallel algorithms}
}

@inproceedings{LianParallel2017,
 author = {Lian, Xiangru and Zhang, Ce and Zhang, Huan and Hsieh, Cho-Jui and Zhang, Wei and Liu, Ji},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Can Decentralized Algorithms Outperform Centralized Algorithms? A Case Study for Decentralized Parallel Stochastic Gradient Descent},
 url = {https://proceedings.neurips.cc/paper/2017/file/f75526659f31040afeb61cb7133e4e6d-Paper.pdf},
 volume = {30},
 year = {2017}
}



@inproceedings{BonawitzFLScale2019,
 author = {Bonawitz, Keith and Eichner, Hubert and Grieskamp, Wolfgang and Huba, Dzmitry and Ingerman, Alex and Ivanov, Vladimir and Kiddon, Chlo\'{e} and Kone\v{c}n\'{y}, Jakub and Mazzocchi, Stefano and McMahan, Brendan and Van Overveldt, Timon and Petrou, David and Ramage, Daniel and Roselander, Jason},
 booktitle = {Proceedings of Machine Learning and Systems},
 editor = {A. Talwalkar and V. Smith and M. Zaharia},
 pages = {374--388},
 title = {Towards Federated Learning at Scale: System Design},
 url = {https://proceedings.mlsys.org/paper/2019/file/bd686fd640be98efaae0091fa301e613-Paper.pdf},
 volume = {1},
 year = {2019}
}





@misc{JeongComm2018,
  doi = {10.48550/ARXIV.1811.11479},
  
  url = {https://arxiv.org/abs/1811.11479},
  
  author = {Jeong, Eunjeong and Oh, Seungeun and Kim, Hyesung and Park, Jihong and Bennis, Mehdi and Kim, Seong-Lyun},
  
  keywords = {Machine Learning (cs.LG), Networking and Internet Architecture (cs.NI), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Communication-Efficient On-Device Machine Learning: Federated Distillation and Augmentation under Non-IID Private Data},
  
  publisher = {arXiv},
  
  year = {2018},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@misc{JakubFL2016,
  doi = {10.48550/ARXIV.1610.05492},
  
  url = {https://arxiv.org/abs/1610.05492},
  
  author = {Konečný, Jakub and McMahan, H. Brendan and Yu, Felix X. and Richtárik, Peter and Suresh, Ananda Theertha and Bacon, Dave},
  
  keywords = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Federated Learning: Strategies for Improving Communication Efficiency},
  
  publisher = {arXiv},
  
  year = {2016},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@article{LinBandwithLin,
  doi = {10.48550/ARXIV.1712.01887},
  
  url = {https://arxiv.org/abs/1712.01887},
  
  author = {Lin, Yujun and Han, Song and Mao, Huizi and Wang, Yu and Dally, William J.},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Distributed, Parallel, and Cluster Computing (cs.DC), Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Deep Gradient Compression: Reducing the Communication Bandwidth for Distributed Training},
  
  publisher = {arXiv},
  
  year = {2017},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}



@InProceedings{BagdasaryanFL2018,
  title = 	 {How To Backdoor Federated Learning},
  author =       {Bagdasaryan, Eugene and Veit, Andreas and Hua, Yiqing and Estrin, Deborah and Shmatikov, Vitaly},
  booktitle = 	 {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},
  pages = 	 {2938--2948},
  year = 	 {2020},
  editor = 	 {Chiappa, Silvia and Calandra, Roberto},
  volume = 	 {108},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {26--28 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v108/bagdasaryan20a/bagdasaryan20a.pdf},
  url = 	 {https://proceedings.mlr.press/v108/bagdasaryan20a.html},
  abstract = 	 {Federated models are created by aggregating model updates submittedby participants.  To protect confidentiality of the training data,the aggregator by design has no visibility into how these updates aregenerated.  We show that this makes federated learning vulnerable to amodel-poisoning attack that is significantly more powerful than poisoningattacks that target only the training data.A single or multiple malicious participants can use modelreplacement to introduce backdoor functionality into the joint model,e.g., modify an image classifier so that it assigns an attacker-chosenlabel to images with certain features, or force a word predictor tocomplete certain sentences with an attacker-chosen word.  We evaluatemodel replacement under different assumptions for the standardfederated-learning tasks and show that it greatly outperformstraining-data poisoning.Federated learning employs secure aggregation to protect confidentialityof participants’ local models and thus cannot detect anomalies inparticipants’ contributions to the joint model.  To demonstrate thatanomaly detection would not have been effective in any case, we alsodevelop and evaluate a generic constrain-and-scale technique thatincorporates the evasion of defenses into the attacker’s loss functionduring training.}
}


@inproceedings{BonawitzSecure2017,
author = {Bonawitz, Keith and Ivanov, Vladimir and Kreuter, Ben and Marcedone, Antonio and McMahan, H. Brendan and Patel, Sarvar and Ramage, Daniel and Segal, Aaron and Seth, Karn},
title = {Practical Secure Aggregation for Privacy-Preserving Machine Learning},
year = {2017},
isbn = {9781450349468},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3133956.3133982},
doi = {10.1145/3133956.3133982},
booktitle = {Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security},
pages = {1175–1191},
numpages = {17},
keywords = {machine learning, privacy-preserving protocols, secure aggregation, federated learning},
location = {Dallas, Texas, USA},
series = {CCS '17}
}





@Inbook{GiannakisWireless2015,
author="Giannakis, Georgios B.
and Ling, Qing
and Mateos, Gonzalo
and Schizas, Ioannis D.
and Zhu, Hao",
editor="Glowinski, Roland
and Osher, Stanley J.
and Yin, Wotao",
title="Decentralized Learning for Wireless Communications and Networking",
bookTitle="Splitting Methods in Communication, Imaging, Science, and Engineering",
year="2016",
publisher="Springer International Publishing",
address="Cham",
pages="461--497",
abstract="This chapter deals with decentralized learning algorithms for in-network processing of graph-valued data. A generic learning problem is formulated and recast into a separable form, which is iteratively minimized using the alternating-direction method of multipliers (ADMM) so as to gain the desired degree of parallelization. Without exchanging elements from the distributed training sets and keeping inter-node communications at affordable levels, the local (per-node) learners consent to the desired quantity inferred globally, meaning the one obtained if the entire training data set were centrally available. Impact of the decentralized learning framework to contemporary wireless communications and networking tasks is illustrated through case studies including target tracking using wireless sensor networks, unveiling Internet traffic anomalies, power system state estimation, as well as spectrum cartography for wireless cognitive radio networks.",
isbn="978-3-319-41589-5",
doi="10.1007/978-3-319-41589-5_14",
url="https://doi.org/10.1007/978-3-319-41589-5_14"
}




@INPROCEEDINGS{WangEdge2018,  author={Wang, Shiqiang and Tuor, Tiffany and Salonidis, Theodoros and Leung, Kin K. and Makaya, Christian and He, Ting and Chan, Kevin},  booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications},   title={When Edge Meets Learning: Adaptive Control for Resource-Constrained Distributed Machine Learning},   year={2018},  volume={},  number={},  pages={63-71},  doi={10.1109/INFOCOM.2018.8486403}}


@INPROCEEDINGS{Silos2021,
  author={Li, Qinbin and Diao, Yiqun and Chen, Quan and He, Bingsheng},
  booktitle={2022 IEEE 38th International Conference on Data Engineering (ICDE)}, 
  title={Federated Learning on Non-IID Data Silos: An Experimental Study}, 
  year={2022},
  volume={},
  number={},
  pages={965-978},
  doi={10.1109/ICDE53745.2022.00077}}


@misc{dirichlet20015,
  
  author = {Jonathan Huang},
  
  title = {Maximum likelihood estimation of dirichlet distribution
parameters},
    publisher = {CMU Technique Report},

  year = {2005},
  
}


@article{EvalGan2019,
  author    = {Terrance DeVries and
               Adriana Romero and
               Luis Pineda and
               Graham W. Taylor and
               Michal Drozdzal},
  title     = {On the Evaluation of Conditional GANs},
  journal   = {CoRR},
  volume    = {abs/1907.08175},
  year      = {2019},
  url       = {http://arxiv.org/abs/1907.08175},
  eprinttype = {arXiv},
  eprint    = {1907.08175},
  timestamp = {Tue, 23 Jul 2019 10:54:22 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1907-08175.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}



@article{FrechetD1982,
title = {The Fréchet distance between multivariate normal distributions},
journal = {Journal of Multivariate Analysis},
volume = {12},
number = {3},
pages = {450-455},
year = {1982},
issn = {0047-259X},
doi = {https://doi.org/10.1016/0047-259X(82)90077-X},
url = {https://www.sciencedirect.com/science/article/pii/0047259X8290077X},
author = {D.C Dowson and B.V Landau},
keywords = {Fréchet distance, multivariate normal distributions, covariance matrices},
abstract = {The Fréchet distance between two multivariate normal distributions having means μX, μY and covariance matrices ΣX, ΣY is shown to be given by d2 = |μX − μY|2 + tr(ΣX + ΣY − 2(ΣXΣY)12). The quantity d0 given by d02 = tr(ΣX + ΣY − 2(ΣXΣY)12) is a natural metric on the space of real covariance matrices of given order.}
}


@InProceedings{CelebAData2014,
author = {Liu, Ziwei and Luo, Ping and Wang, Xiaogang and Tang, Xiaoou},
title = {Deep Learning Face Attributes in the Wild},
booktitle = {Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
month = {December},
year = {2015}
}




@article{cohen2017emnist,
  title={EMNIST: an extension of MNIST to handwritten letters},
  author={Cohen, Gregory and Afshar, Saeed and Tapson, Jonathan and van Schaik, Andr{\'e}},
  journal={arXiv preprint arXiv:1702.05373},
  year={2017}
}


@misc{DPPapernot2016,
  doi = {10.48550/ARXIV.1610.05755},
  
  url = {https://arxiv.org/abs/1610.05755},
  
  author = {Papernot, Nicolas and Abadi, Martín and Erlingsson, Úlfar and Goodfellow, Ian and Talwar, Kunal},
  
  keywords = {Machine Learning (stat.ML), Cryptography and Security (cs.CR), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Semi-supervised Knowledge Transfer for Deep Learning from Private Training Data},
  
  publisher = {arXiv},
  
  year = {2016},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@article{TRAN2021245,
title = {An efficient approach for privacy preserving decentralized deep learning models based on secure multi-party computation},
journal = {Neurocomputing},
volume = {422},
pages = {245-262},
year = {2021},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2020.10.014},
url = {https://www.sciencedirect.com/science/article/pii/S0925231220315095},
author = {Anh-Tu Tran and The-Dung Luong and Jessada Karnjana and Van-Nam Huynh},
keywords = {Federated learning, Secure multi-party computation, Deep learning, Privacy preservation},
abstract = {This paper aims to develop a new efficient framework named Secure Decentralized Training Framework (SDTF) for Privacy Preserving Deep Learning models. The main feature of the proposed framework is its capable of working on a decentralized network setting that does not need a trusted third-party server while simultaneously ensuring the privacy of local data with a low cost of communication bandwidth. Particularly, we first propose a so-called Efficient Secure Sum Protocol (ESSP) that enables a large group of parties to jointly calculate a sum of private inputs. ESSP can work not only with integer number but also with floating point number without any data conversion. We then propose a Secure Model Sharing Protocol that enables a group of parties securely train and share the local models to be aggregated into a global model. Secure Model Sharing Protocol exploits randomization techniques and ESSP to protect local models from any honest-but-curious party even n-2 of n parties colluding. Eventually, these protocols are employed for collaborative training decentralized deep learning models. We conduct theoretical evaluation of privacy and communication cost as well as empirical experiments on balance class image datasets (MNIST) and an unbalance class text dataset (UCI SMS Spam). These experiments demonstrate the proposed approach can obtain high accuracy (i.e. 97\% baseline accuracy in only 10 training rounds with MNIST, 100 training rounds with SMS Spam) and robust to the heterogeneity decentralized network, with non-IID and unbalance data distributions. We also show a reduction in required rounds of training to achieve the accuracy baseline by 5× as compared to Downpour SGD. It is shown that the proposed approach can achieve both the privacy at the level of cryptographic approaches and efficiency at the level of randomization techniques, while it also retains higher model’s utility than differential privacy approaches.}
}


@misc{HoangMultiGs2017,
  doi = {10.48550/ARXIV.1708.02556},
  
  url = {https://arxiv.org/abs/1708.02556},
  
  author = {Hoang, Quan and Nguyen, Tu Dinh and Le, Trung and Phung, Dinh},
  
  keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Multi-Generator Generative Adversarial Nets},
  
  publisher = {arXiv},
  
  year = {2017},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@misc{Kunartabular2021,
  doi = {10.48550/ARXIV.2108.10064},
  
  url = {https://arxiv.org/abs/2108.10064},
  
  author = {Kunar, Aditya},
  
  keywords = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Effective and Privacy preserving Tabular Data Synthesizing},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@InProceedings{FrigerioSeq2019,
author="Frigerio, Lorenzo
and de Oliveira, Anderson Santana
and Gomez, Laurent
and Duverger, Patrick",
editor="Dhillon, Gurpreet
and Karlsson, Fredrik
and Hedstr{\"o}m, Karin
and Z{\'u}quete, Andr{\'e}",
title="Differentially Private Generative Adversarial Networks for Time Series, Continuous, and Discrete Open Data",
booktitle="ICT Systems Security and Privacy Protection",
year="2019",
publisher="Springer International Publishing",
address="Cham",
pages="151--164",
abstract="Open data plays a fundamental role in the 21st century by stimulating economic growth and by enabling more transparent and inclusive societies. However, it is always difficult to create new high-quality datasets with the required privacy guarantees for many use cases. In this paper, we developed a differential privacy framework for privacy preserving data publishing using Generative Adversarial Networks. It can be easily adapted to different use cases, from the generation of time-series, to continuous, and discrete data. We demonstrate the efficiency of our approach on real datasets from the French public administration and classic benchmark datasets. Our results maintain both the original distribution of the features and the correlations among them, at the same time providing a good level of privacy.",
isbn="978-3-030-22312-0"
}






@inproceedings{MIAttack2015,
author = {Fredrikson, Matt and Jha, Somesh and Ristenpart, Thomas},
title = {Model Inversion Attacks That Exploit Confidence Information and Basic Countermeasures},
year = {2015},
isbn = {9781450338325},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2810103.2813677},
doi = {10.1145/2810103.2813677},
abstract = {Machine-learning (ML) algorithms are increasingly utilized in privacy-sensitive applications such as predicting lifestyle choices, making medical diagnoses, and facial recognition. In a model inversion attack, recently introduced in a case study of linear classifiers in personalized medicine by Fredrikson et al., adversarial access to an ML model is abused to learn sensitive genomic information about individuals. Whether model inversion attacks apply to settings outside theirs, however, is unknown. We develop a new class of model inversion attack that exploits confidence values revealed along with predictions. Our new attacks are applicable in a variety of settings, and we explore two in depth: decision trees for lifestyle surveys as used on machine-learning-as-a-service systems and neural networks for facial recognition. In both cases confidence values are revealed to those with the ability to make prediction queries to models. We experimentally show attacks that are able to estimate whether a respondent in a lifestyle survey admitted to cheating on their significant other and, in the other context, show how to recover recognizable images of people's faces given only their name and access to the ML model. We also initiate experimental exploration of natural countermeasures, investigating a privacy-aware decision tree training algorithm that is a simple variant of CART learning, as well as revealing only rounded confidence values. The lesson that emerges is that one can avoid these kinds of MI attacks with negligible degradation to utility.},
booktitle = {Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security},
pages = {1322–1333},
numpages = {12},
keywords = {privacy, machine learning, attacks},
location = {Denver, Colorado, USA},
series = {CCS '15}
}

@inproceedings{SongLink2017,
author = {Song, Congzheng and Ristenpart, Thomas and Shmatikov, Vitaly},
title = {Machine Learning Models That Remember Too Much},
year = {2017},
isbn = {9781450349468},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3133956.3134077},
doi = {10.1145/3133956.3134077},
abstract = {Machine learning (ML) is becoming a commodity. Numerous ML frameworks and services are available to data holders who are not ML experts but want to train predictive models on their data. It is important that ML models trained on sensitive inputs (e.g., personal images or documents) not leak too much information about the training data.We consider a malicious ML provider who supplies model-training code to the data holder, does emph{not} observe the training, but then obtains white- or black-box access to the resulting model. In this setting, we design and implement practical algorithms, some of them very similar to standard ML techniques such as regularization and data augmentation, that "memorize" information about the training dataset in the modeltextemdash yet the model is as accurate and predictive as a conventionally trained model. We then explain how the adversary can extract memorized information from the model. We evaluate our techniques on standard ML tasks for image classification (CIFAR10), face recognition (LFW and FaceScrub), and text analysis (20 Newsgroups and IMDB). In all cases, we show how our algorithms create models that have high predictive power yet allow accurate extraction of subsets of their training data.},
booktitle = {Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security},
pages = {587–601},
numpages = {15},
location = {Dallas, Texas, USA},
series = {CCS '17}
}

@ARTICLE{PhongHomo2018,
  author={Phong, Le Trieu and Aono, Yoshinori and Hayashi, Takuya and Wang, Lihua and Moriai, Shiho},
  journal={IEEE Transactions on Information Forensics and Security}, 
  title={Privacy-Preserving Deep Learning via Additively Homomorphic Encryption}, 
  year={2018},
  volume={13},
  number={5},
  pages={1333-1345},
  doi={10.1109/TIFS.2017.2787987}}



  @article {BeaulieuClinical2017,
	author = {Beaulieu-Jones, Brett K. and Wu, Zhiwei Steven and Williams, Chris and Greene, Casey S.},
	title = {Privacy-preserving generative deep neural networks support clinical data sharing},
	elocation-id = {159756},
	year = {2017},
	doi = {10.1101/159756},
	publisher = {Cold Spring Harbor Laboratory},
	abstract = {Though it is widely recognized that data sharing enables faster scientific progress, the sensible need to protect participant privacy hampers this practice in medicine. We train deep neural networks that generate synthetic subjects closely resembling study participants. Using the SPRINT trial as an example, we show that machine-learning models built from simulated participants generalize to the original dataset. We incorporate differential privacy, which offers strong guarantees on the likelihood that a subject could be identified as a member of the trial. Investigators who have compiled a dataset can use our method to provide a freely accessible public version that enables other scientists to perform discovery-oriented analyses. Generated data can be released alongside analytical code to enable fully reproducible workflows, even when privacy is a concern. By addressing data sharing challenges, deep neural networks can facilitate the rigorous and reproducible investigation of clinical datasets.One Sentence Summary Deep neural networks can generate shareable biomedical data to allow reanalysis while preserving the privacy of study participants.},
	URL = {https://www.biorxiv.org/content/early/2017/07/05/159756},
	eprint = {https://www.biorxiv.org/content/early/2017/07/05/159756.full.pdf},
	journal = {bioRxiv}
}




@article{SweeneyKAno2002,
author = {Sweeney, Latanya},
title = {K-Anonymity: A Model for Protecting Privacy},
year = {2002},
issue_date = {October 2002},
publisher = {World Scientific Publishing Co., Inc.},
address = {USA},
volume = {10},
number = {5},
issn = {0218-4885},
url = {https://doi.org/10.1142/S0218488502001648},
doi = {10.1142/S0218488502001648},
abstract = {Consider a data holder, such as a hospital or a bank, that has a privately held collection of person-specific, field structured data. Suppose the data holder wants to share a version of the data with researchers. How can a data holder release a version of its private data with scientific guarantees that the individuals who are the subjects of the data cannot be re-identified while the data remain practically useful? The solution provided in this paper includes a formal protection model named k-anonymity and a set of accompanying policies for deployment. A release provides k-anonymity protection if the information for each person contained in the release cannot be distinguished from at least k-1 individuals whose information also appears in the release. This paper also examines re-identification attacks that can be realized on releases that adhere to k- anonymity unless accompanying policies are respected. The k-anonymity protection model is important because it forms the basis on which the real-world systems known as Datafly, µ-Argus and k-Similar provide guarantees of privacy protection.},
journal = {Int. J. Uncertain. Fuzziness Knowl.-Based Syst.},
month = {oct},
pages = {557–570},
numpages = {14},
keywords = {privacy, re-identification, data anonymity, data privacy, data fusion}
}


@article{BarbaroExposed2006,
author = {Barbaro, Michael and Zeller, Tom},
year = {2006},
month = {01},
pages = {},
title = {A Face is exposed for AOL searcher no. 4417749},
journal = {New York Times}
}


@article{MontjoyeUnique2013,
author = {Montjoye, Yves-Alexandre and Hidalgo, Cesar and Verleysen, Michel and Blondel, Vincent},
year = {2013},
month = {03},
pages = {1376},
title = {Unique in the Crowd: The Privacy Bounds of Human Mobility},
volume = {3},
journal = {Scientific reports},
doi = {10.1038/srep01376}
}

@article{ZhangDRelease2017,
author = {Zhang, Jun and Cormode, Graham and Procopiuc, Cecilia M. and Srivastava, Divesh and Xiao, Xiaokui},
title = {PrivBayes: Private Data Release via Bayesian Networks},
year = {2017},
issue_date = {December 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {42},
number = {4},
issn = {0362-5915},
url = {https://doi.org/10.1145/3134428},
doi = {10.1145/3134428},
abstract = {Privacy-preserving data publishing is an important problem that has been the focus of extensive study. The state-of-the-art solution for this problem is differential privacy, which offers a strong degree of privacy protection without making restrictive assumptions about the adversary. Existing techniques using differential privacy, however, cannot effectively handle the publication of high-dimensional data. In particular, when the input dataset contains a large number of attributes, existing methods require injecting a prohibitive amount of noise compared to the signal in the data, which renders the published data next to useless.To address the deficiency of the existing methods, this paper presents PrivBayes, a differentially private method for releasing high-dimensional data. Given a dataset D, PrivBayes first constructs a Bayesian network N, which (i) provides a succinct model of the correlations among the attributes in D and (ii) allows us to approximate the distribution of data in D using a set P of low-dimensional marginals of D. After that, PrivBayes injects noise into each marginal in P to ensure differential privacy and then uses the noisy marginals and the Bayesian network to construct an approximation of the data distribution in D. Finally, PrivBayes samples tuples from the approximate distribution to construct a synthetic dataset, and then releases the synthetic data. Intuitively, PrivBayes circumvents the curse of dimensionality, as it injects noise into the low-dimensional marginals in P instead of the high-dimensional dataset D. Private construction of Bayesian networks turns out to be significantly challenging, and we introduce a novel approach that uses a surrogate function for mutual information to build the model more accurately. We experimentally evaluate PrivBayes on real data and demonstrate that it significantly outperforms existing solutions in terms of accuracy.},
journal = {ACM Trans. Database Syst.},
month = {oct},
articleno = {25},
numpages = {41},
keywords = {bayesian network, Differential privacy, synthetic data generation}
}

@inproceedings{DPClustering2015,
author = {Su, Dong and Cao, Jianneng and Li, Ninghui and Bertino, Elisa and Jin, Hongxia},
title = {Differentially Private K-Means Clustering},
year = {2016},
isbn = {9781450339353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2857705.2857708},
doi = {10.1145/2857705.2857708},
abstract = {There are two broad approaches for differentially private data analysis. The interactive approach aims at developing customized differentially private algorithms for various data mining tasks. The non-interactive approach aims at developing differentially private algorithms that can output a synopsis of the input dataset, which can then be used to support various data mining tasks. In this paper we study the effectiveness of the two approaches on differentially private k-means clustering. We develop techniques to analyze the empirical error behaviors of the existing interactive and non-interactive approaches. Based on the analysis, we propose an improvement of DPLloyd which is a differentially private version of the Lloyd algorithm. We also propose a non-interactive approach EUGkM which publishes a differentially private synopsis for k-means clustering. Results from extensive and systematic experiments support our analysis and demonstrate the effectiveness of our improvement on DPLloyd and the proposed EUGkM algorithm.},
booktitle = {Proceedings of the Sixth ACM Conference on Data and Application Security and Privacy},
pages = {26–37},
numpages = {12},
keywords = {differential privacy, private data publishing, k-means clustering},
location = {New Orleans, Louisiana, USA},
series = {CODASPY '16}
}



@misc{DeRecog2022,
  doi = {10.48550/ARXIV.2204.13650},
  
  url = {https://arxiv.org/abs/2204.13650},
  
  author = {De, Soham and Berrada, Leonard and Hayes, Jamie and Smith, Samuel L. and Balle, Borja},
  
  keywords = {Machine Learning (cs.LG), Cryptography and Security (cs.CR), Computer Vision and Pattern Recognition (cs.CV), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Unlocking High-Accuracy Differentially Private Image Classification through Scale},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {Creative Commons Attribution 4.0 International}
}


@misc{CaldasfederatedD2018,
  doi = {10.48550/ARXIV.1812.01097},
  
  url = {https://arxiv.org/abs/1812.01097},
  
  author = {Caldas, Sebastian and Duddu, Sai Meher Karthik and Wu, Peter and Li, Tian and Konečný, Jakub and McMahan, H. Brendan and Smith, Virginia and Talwalkar, Ameet},
  
  keywords = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {LEAF: A Benchmark for Federated Settings},
  
  publisher = {arXiv},
  
  year = {2018},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@article{HufederatedD2022,
author = {Hu, Sixu and Li, Yuan and Liu, Xu and Li, Qinbin and Wu, Zhaomin and He, Bingsheng},
title = {The OARF Benchmark Suite: Characterization and Implications for Federated Learning Systems},
year = {2022},
issue_date = {August 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {4},
issn = {2157-6904},
url = {https://doi.org/10.1145/3510540},
doi = {10.1145/3510540},
abstract = {This article presents and characterizes an Open Application Repository for Federated Learning (OARF), a benchmark suite for federated machine learning systems. Previously available benchmarks for federated learning (FL) have focused mainly on synthetic datasets and use a limited number of applications. OARF mimics more realistic application scenarios with publicly available datasets as different data silos in image, text, and structured data. Our characterization shows that the benchmark suite is diverse in data size, distribution, feature distribution, and learning task complexity. The extensive evaluations with reference implementations show the future research opportunities for important aspects of FL systems. We have developed reference implementations, and evaluated the important aspects of FL, including model accuracy, communication cost, throughput, and convergence time. Through these evaluations, we discovered some interesting findings such as FL can effectively increase end-to-end throughput. The code of OARF is publicly available on GitHub.1},
journal = {ACM Trans. Intell. Syst. Technol.},
month = {jun},
articleno = {63},
numpages = {32},
keywords = {framework, dataset, benchmark, machine learning, Federated learning}
}





@inproceedings{BonawitzCrypto2017,
author = {Bonawitz, Keith and Ivanov, Vladimir and Kreuter, Ben and Marcedone, Antonio and McMahan, H. Brendan and Patel, Sarvar and Ramage, Daniel and Segal, Aaron and Seth, Karn},
title = {Practical Secure Aggregation for Privacy-Preserving Machine Learning},
year = {2017},
isbn = {9781450349468},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3133956.3133982},
doi = {10.1145/3133956.3133982},
abstract = {We design a novel, communication-efficient, failure-robust protocol for secure aggregation of high-dimensional data. Our protocol allows a server to compute the sum of large, user-held data vectors from mobile devices in a secure manner (i.e. without learning each user's individual contribution), and can be used, for example, in a federated learning setting, to aggregate user-provided model updates for a deep neural network. We prove the security of our protocol in the honest-but-curious and active adversary settings, and show that security is maintained even if an arbitrarily chosen subset of users drop out at any time. We evaluate the efficiency of our protocol and show, by complexity analysis and a concrete implementation, that its runtime and communication overhead remain low even on large data sets and client pools. For 16-bit input values, our protocol offers $1.73 x communication expansion for 210 users and 220-dimensional vectors, and 1.98 x expansion for 214 users and 224-dimensional vectors over sending data in the clear.},
booktitle = {Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security},
pages = {1175–1191},
numpages = {17},
keywords = {machine learning, privacy-preserving protocols, federated learning, secure aggregation},
location = {Dallas, Texas, USA},
series = {CCS '17}
}


@misc{xu2022mace,
      title={MACE: A Flexible Framework for Membership Privacy Estimation in Generative Models}, 
      author={Yixi Xu and Sumit Mukherjee and Xiyang Liu and Shruti Tople and Rahul Dodhia and Juan Lavista Ferres},
      year={2022},
      eprint={2009.05683},
      archivePrefix={arXiv},
      primaryClass={cs.CR}
}





@article{DP_GDPR_2019,
author = {Hölzel, Julian},
year = {2019},
month = {01},
pages = {184-196},
title = {Differential Privacy and the GDPR},
volume = {5},
journal = {European Data Protection Law Review},
doi = {10.21552/edpl/2019/2/8}
}


@InProceedings{HsiehNonIIDData2019,
  title = 	 {The Non-{IID} Data Quagmire of Decentralized Machine Learning},
  author =       {Hsieh, Kevin and Phanishayee, Amar and Mutlu, Onur and Gibbons, Phillip},
  booktitle = 	 {Proceedings of the 37th International Conference on Machine Learning},
  pages = 	 {4387--4398},
  year = 	 {2020},
  editor = 	 {III, Hal Daumé and Singh, Aarti},
  volume = 	 {119},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {13--18 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v119/hsieh20a/hsieh20a.pdf},
  url = 	 {https://proceedings.mlr.press/v119/hsieh20a.html},
  abstract = 	 {Many large-scale machine learning (ML) applications need to perform decentralized learning over datasets generated at different devices and locations. Such datasets pose a significant challenge to decentralized learning because their different contexts result in significant data distribution skew across devices/locations. In this paper, we take a step toward better understanding this challenge by presenting a detailed experimental study of decentralized DNN training on a common type of data skew: skewed distribution of data labels across devices/locations. Our study shows that: (i) skewed data labels are a fundamental and pervasive problem for decentralized learning, causing significant accuracy loss across many ML applications, DNN models, training datasets, and decentralized learning algorithms; (ii) the problem is particularly challenging for DNN models with batch normalization; and (iii) the degree of data skew is a key determinant of the difficulty of the problem. Based on these findings, we present SkewScout, a system-level approach that adapts the communication frequency of decentralized learning algorithms to the (skew-induced) accuracy loss between data partitions. We also show that group normalization can recover much of the accuracy loss of batch normalization.}
}


@inproceedings{dwork2010differential,
  title={Differential privacy in new settings},
  author={Dwork, Cynthia},
  booktitle={Proceedings of the twenty-first annual ACM-SIAM symposium on Discrete Algorithms},
  pages={174--183},
  year={2010},
  organization={SIAM}
}









@article{mirza2014conditional,
  title={Conditional generative adversarial nets},
  author={Mirza, Mehdi and Osindero, Simon},
  journal={arXiv preprint arXiv:1411.1784},
  year={2014}
}

@inproceedings{arjovsky2017wasserstein,
  title={Wasserstein generative adversarial networks},
  author={Arjovsky, Martin and Chintala, Soumith and Bottou, L{\'e}on},
  booktitle={International conference on machine learning},
  pages={214--223},
  year={2017},
  organization={PMLR}
}

@article{SuntimeGANs2020,
  author    = {He Sun and
               Zhun Deng and
               Hui Chen and
               David C. Parkes},
  title     = {Decision-Aware Conditional GANs for Time Series Data},
  journal   = {CoRR},
  volume    = {abs/2009.12682},
  year      = {2020},
  url       = {https://arxiv.org/abs/2009.12682},
  eprinttype = {arXiv},
  eprint    = {2009.12682},
  timestamp = {Wed, 30 Sep 2020 16:16:22 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2009-12682.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{SpampinatoVideoGAN2018,
  title={Adversarial framework for unsupervised learning of motion dynamics in videos},
  author={Spampinato, Concetto and Palazzo, Simone and D’Oro, P and Giordano, Daniela and Shah, Mubarak},
  journal={International Journal of Computer Vision},
  volume={128},
  number={5},
  pages={1378--1397},
  year={2020},
  publisher={Springer}
}



@InProceedings{KimDomain2017,
  title = 	 {Learning to Discover Cross-Domain Relations with Generative Adversarial Networks},
  author =       {Taeksoo Kim and Moonsu Cha and Hyunsoo Kim and Jung Kwon Lee and Jiwon Kim},
  booktitle = 	 {Proceedings of the 34th International Conference on Machine Learning},
  pages = 	 {1857--1865},
  year = 	 {2017},
  editor = 	 {Precup, Doina and Teh, Yee Whye},
  volume = 	 {70},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {06--11 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v70/kim17a/kim17a.pdf},
  url = 	 {https://proceedings.mlr.press/v70/kim17a.html},
  abstract = 	 {While humans easily recognize relations between data from different domains without any supervision, learning to automatically discover them is in general very challenging and needs many ground-truth pairs that illustrate the relations. To avoid costly pairing, we address the task of discovering cross-domain relations given unpaired data. We propose a method based on a generative adversarial network that learns to discover relations between different domains (DiscoGAN). Using the discovered relations, our proposed network successfully transfers style from one domain to another while preserving key attributes such as orientation and face identity.}
}


@InProceedings{ImagesGANs2018,
author = {Karras, Tero and Laine, Samuli and Aila, Timo},
title = {A Style-Based Generator Architecture for Generative Adversarial Networks},
booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2019}
}




@misc{AshrapovtabularGAN2010,
  doi = {10.48550/ARXIV.2010.00638},
  
  url = {https://arxiv.org/abs/2010.00638},
  
  author = {Ashrapov, Insaf},
  
  keywords = {Machine Learning (cs.LG), Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Tabular GANs for uneven distribution},
  
  publisher = {arXiv},
  
  year = {2020},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@article{SaxenaSurveyGANs2020,
author = {Saxena, Divya and Cao, Jiannong},
title = {Generative Adversarial Networks (GANs): Challenges, Solutions, and Future Directions},
year = {2021},
issue_date = {April 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/3446374},
doi = {10.1145/3446374},
abstract = {Generative Adversarial Networks (GANs) is a novel class of deep generative models that has recently gained significant attention. GANs learn complex and high-dimensional distributions implicitly over images, audio, and data. However, there exist major challenges in training of GANs, i.e., mode collapse, non-convergence, and instability, due to inappropriate design of network architectre, use of objective function, and selection of optimization algorithm. Recently, to address these challenges, several solutions for better design and optimization of GANs have been investigated based on techniques of re-engineered network architectures, new objective functions, and alternative optimization algorithms. To the best of our knowledge, there is no existing survey that has particularly focused on the broad and systematic developments of these solutions. In this study, we perform a comprehensive survey of the advancements in GANs design and optimization solutions proposed to handle GANs challenges. We first identify key research issues within each design and optimization technique and then propose a new taxonomy to structure solutions by key research issues. In accordance with the taxonomy, we provide a detailed discussion on different GANs variants proposed within each solution and their relationships. Finally, based on the insights gained, we present promising research directions in this rapidly growing field.},
journal = {ACM Comput. Surv.},
month = {may},
articleno = {63},
numpages = {42},
keywords = {GANs challenges, deep Generative models, GANs variants, GANs, GANs applications, computer vision, mode collapse, Generative Adversarial Networks, Image generation, GANs Survey, Deep learning}
}




@misc{Durugkarmode2016,
  doi = {10.48550/ARXIV.1611.01673},
  
  url = {https://arxiv.org/abs/1611.01673},
  
  author = {Durugkar, Ishan and Gemp, Ian and Mahadevan, Sridhar},
  
  keywords = {Machine Learning (cs.LG), Multiagent Systems (cs.MA), Neural and Evolutionary Computing (cs.NE), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Generative Multi-Adversarial Networks},
  
  publisher = {arXiv},
  
  year = {2016},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{sNguyenDual2017,
 author = {Nguyen, Tu and Le, Trung and Vu, Hung and Phung, Dinh},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Dual Discriminator Generative Adversarial Nets},
 url = {https://proceedings.neurips.cc/paper/2017/file/e60e81c4cbe5171cd654662d9887aec2-Paper.pdf},
 volume = {30},
 year = {2017}
}




@misc{NeyshaburStabilizing2017,
  doi = {10.48550/ARXIV.1705.07831},
  
  url = {https://arxiv.org/abs/1705.07831},
  
  author = {Neyshabur, Behnam and Bhojanapalli, Srinadh and Chakrabarti, Ayan},
  
  keywords = {Machine Learning (cs.LG), Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Stabilizing GAN Training with Multiple Random Projections},
  
  publisher = {arXiv},
  
  year = {2017},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@misc{MordidoDropout2018,
  doi = {10.48550/ARXIV.1807.11346},
  
  url = {https://arxiv.org/abs/1807.11346},
  
  author = {Mordido, Gonçalo and Yang, Haojin and Meinel, Christoph},
  
  keywords = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Dropout-GAN: Learning from a Dynamic Ensemble of Discriminators},
  
  publisher = {arXiv},
  
  year = {2018},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}




@inproceedings{fan2020survey,
  title={A survey of differentially private generative adversarial networks},
  author={Fan, Liyue},
  booktitle={The AAAI Workshop on Privacy-Preserving Artificial Intelligence},
  pages={8},
  year={2020}
}







@inproceedings{LiMemML20013,
author = {Li, Ninghui and Qardaji, Wahbeh and Su, Dong and Wu, Yi and Yang, Weining},
title = {Membership Privacy: A Unifying Framework for Privacy Definitions},
year = {2013},
isbn = {9781450324779},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2508859.2516686},
doi = {10.1145/2508859.2516686},
abstract = {We introduce a novel privacy framework that we call Membership Privacy. The framework includes positive membership privacy, which prevents the adversary from significantly increasing its ability to conclude that an entity is in the input dataset, and negative membership privacy, which prevents leaking of non-membership. These notions are parameterized by a family of distributions that captures the adversary's prior knowledge. The power and flexibility of the proposed framework lies in the ability to choose different distribution families to instantiate membership privacy. Many privacy notions in the literature are equivalent to membership privacy with interesting distribution families, including differential privacy, differential identifiability, and differential privacy under sampling. Casting these notions into the framework leads to deeper understanding of the strengthes and weaknesses of these notions, as well as their relationships to each other. The framework also provides a principled approach to developing new privacy notions under which better utility can be achieved than what is possible under differential privacy.},
booktitle = {Proceedings of the 2013 ACM SIGSAC Conference on Computer &amp; Communications Security},
pages = {889–900},
numpages = {12},
keywords = {privacy notions, differential privacy, membership privacy},
location = {Berlin, Germany},
series = {CCS '13}
}

@INPROCEEDINGS{ShokriMemML2016,
  author={Shokri, Reza and Stronati, Marco and Song, Congzheng and Shmatikov, Vitaly},
  booktitle={2017 IEEE Symposium on Security and Privacy (SP)}, 
  title={Membership Inference Attacks Against Machine Learning Models}, 
  year={2017},
  volume={},
  number={},
  pages={3-18},
  doi={10.1109/SP.2017.41}}



@inproceedings{FredriksonInvML2016,
author = {Fredrikson, Matthew and Lantz, Eric and Jha, Somesh and Lin, Simon and Page, David and Ristenpart, Thomas},
title = {Privacy in Pharmacogenetics: An End-to-End Case Study of Personalized Warfarin Dosing},
year = {2014},
isbn = {9781931971157},
publisher = {USENIX Association},
address = {USA},
abstract = {We initiate the study of privacy in pharmacogenetics, wherein machine learning models are used to guide medical treatments based on a patient's genotype and background. Performing an in-depth case study on privacy in personalized warfarin dosing, we show that suggested models carry privacy risks, in particular because attackers can perform what we call model inversion: an attacker, given the model and some demographic information about a patient, can predict the patient's genetic markers.As differential privacy (DP) is an oft-proposed solution for medical settings such as this, we evaluate its effectiveness for building private versions of pharmacogenetic models. We show that DP mechanisms prevent our model inversion attacks when the privacy budget is carefully selected. We go on to analyze the impact on utility by performing simulated clinical trials with DP dosing models. We find that for privacy budgets effective at preventing attacks, patients would be exposed to increased risk of stroke, bleeding events, and mortality. We conclude that current DP mechanisms do not simultaneously improve genomic privacy while retaining desirable clinical efficacy, highlighting the need for new mechanisms that should be evaluated in situ using the general methodology introduced by our work.},
booktitle = {Proceedings of the 23rd USENIX Conference on Security Symposium},
pages = {17–32},
numpages = {16},
location = {San Diego, CA},
series = {SEC'14}
}

@misc{WangInvML2018,
  doi = {10.48550/ARXIV.1803.02596},
  
  url = {https://arxiv.org/abs/1803.02596},
  
  author = {Wang, Yu-Xiang},
  
  keywords = {Machine Learning (stat.ML), Machine Learning (cs.LG), Methodology (stat.ME), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Revisiting differentially private linear regression: optimal and adaptive prediction &amp; estimation in unbounded domain},
  
  publisher = {arXiv},
  
  year = {2018},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}




@misc{AtenieseMI2013,
  doi = {10.48550/ARXIV.1306.4447},
  
  url = {https://arxiv.org/abs/1306.4447},
  
  author = {Ateniese, Giuseppe and Felici, Giovanni and Mancini, Luigi V. and Spognardi, Angelo and Villani, Antonio and Vitali, Domenico},
  
  keywords = {Cryptography and Security (cs.CR), Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Hacking Smart Machines with Smarter Ones: How to Extract Meaningful Data from Machine Learning Classifiers},
  
  publisher = {arXiv},
  
  year = {2013},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}



@misc{KimMemoryGAN2018,
  doi = {10.48550/ARXIV.1803.01500},
  
  url = {https://arxiv.org/abs/1803.01500},
  
  author = {Kim, Youngjin and Kim, Minjung and Kim, Gunhee},
  
  keywords = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Memorization Precedes Generation: Learning Unsupervised GANs with Memory Networks},
  
  publisher = {arXiv},
  
  year = {2018},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}



@inproceedings{Erlingsson_2014,
	doi = {10.1145/2660267.2660348},
  
	url = {https://doi.org/10.1145%2F2660267.2660348},
  
	year = 2014,
	month = {nov},
  
	publisher = {{ACM}
},
  
	author = {{\'{U}}lfar Erlingsson and Vasyl Pihur and Aleksandra Korolova},
  
	title = {{RAPPOR}},
  
	booktitle = {Proceedings of the 2014 {ACM} {SIGSAC} Conference on Computer and Communications Security}
}}



  
@misc{HolohanLaplace2018,
  doi = {10.48550/ARXIV.1808.10410},
  
  url = {https://arxiv.org/abs/1808.10410},
  
  author = {Holohan, Naoise and Antonatos, Spiros and Braghin, Stefano and Mac Aonghusa, Pól},
  
  keywords = {Cryptography and Security (cs.CR), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {The Bounded Laplace Mechanism in Differential Privacy},
  
  publisher = {arXiv},
  
  year = {2018},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@inproceedings{zhou2021flora,
  title={FLoRA: Single-shot Hyper-parameter Optimization for Federated Learning},
  author={Zhou, Yi and Ram, Parikshit and Salonidis, Theodoros and Angel, Nathalie Baracaldo and Samulowitz, Horst and Ludwig, Heiko},
  booktitle={Annual Conference on Neural Information Processing Systems},
  year={2021}
}


@article{khodak2021federated,
  title={Federated hyperparameter tuning: Challenges, baselines, and connections to weight-sharing},
  author={Khodak, Mikhail and Tu, Renbo and Li, Tian and Li, Liam and Balcan, Maria-Florina F and Smith, Virginia and Talwalkar, Ameet},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={19184--19197},
  year={2021}
}


@inproceedings{FarrandMST20,
  author    = {Tom Farrand and
               Fatemehsadat Mireshghallah and
               Sahib Singh and
               Andrew Trask},
  editor    = {Benyu Zhang and
               Raluca Ada Popa and
               Matei Zaharia and
               Guofei Gu and
               Shouling Ji},
  title     = {Neither Private Nor Fair: Impact of Data Imbalance on Utility and
               Fairness in Differential Privacy},
  booktitle = {PPMLP'20: Proceedings of the 2020 Workshop on Privacy-Preserving Machine
               Learning in Practice, Virtual Event, USA, November, 2020},
  pages     = {15--19},
  publisher = {{ACM}},
  year      = {2020},
  url       = {https://doi.org/10.1145/3411501.3419419},
  doi       = {10.1145/3411501.3419419},
  timestamp = {Wed, 17 Nov 2021 13:50:58 +0100},
  biburl    = {https://dblp.org/rec/conf/ccs/FarrandMST20.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@misc{Zhougridsearch2022,
  doi = {10.48550/ARXIV.2202.08338},
  
  url = {https://arxiv.org/abs/2202.08338},
  
  author = {Zhou, Yi and Ram, Parikshit and Salonidis, Theodoros and Baracaldo, Nathalie and Samulowitz, Horst and Ludwig, Heiko},
  
  keywords = {Machine Learning (cs.LG), Distributed, Parallel, and Cluster Computing (cs.DC), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Single-shot Hyper-parameter Optimization for Federated Learning: A General Algorithm &amp; Analysis},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {Creative Commons Attribution 4.0 International}
}
@INPROCEEDINGS{LiTuning2021,  author={Li, Zhiyuan and Li, Hao and Zhang, Mingyang},  booktitle={2021 IEEE 7th International Conference on Cloud Computing and Intelligent Systems (CCIS)},   title={Hyper-parameter Tuning of Federated Learning Based on Particle Swarm Optimization},   year={2021},  volume={},  number={},  pages={99-103},  doi={10.1109/CCIS53392.2021.9754676}}



@article{shoham2019overcoming,
  title={Overcoming forgetting in federated learning on non-iid data},
  author={Shoham, Neta and Avidor, Tomer and Keren, Aviv and Israel, Nadav and Benditkis, Daniel and Mor-Yosef, Liron and Zeitak, Itai},
  journal={arXiv preprint arXiv:1910.07796},
  year={2019}
}

@article{goodfellow2013empirical,
  title={An empirical investigation of catastrophic forgetting in gradient-based neural networks},
  author={Goodfellow, Ian J and Mirza, Mehdi and Xiao, Da and Courville, Aaron and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1312.6211},
  year={2013}
}